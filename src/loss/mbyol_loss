
import copy
import torch
import torch.nn as nn
import torch.nn.functional as F
from mmengine.model import BaseModule
from mmpretrain.registry import MODELS

class MBYOLLoss(BaseModule):
    """
    Combined Loss for M-BYOL.
    L_total = lambda_recon * L_mae + lambda_distill * L_byol
    """
    def __init__(self,
                 mae_loss_cfg: dict,
                 lambda_recon: float = 1.0,
                 lambda_distill: float = 1.0):
        super().__init__()
        # Import existings MAE loss logic
        self.mae_loss = MODELS.build(mae_loss_cfg)
        self.lambda_recon = lambda_recon
        self.lambda_distill = lambda_distill

    def byol_loss_func(self, p, z):
        """Negative Cosine Similarity"""
        p = F.normalize(p, dim=-1, p=2)
        z = F.normalize(z, dim=-1, p=2)
        return 2 - 2 * (p * z).sum(dim=-1).mean()

    def forward(self, outputs: dict):
        """
        Args:
            outputs (dict): output from MBYOL.forward()
        """
        # 1. Calculate MAE Loss (Reconstruction)
        # Using the helper from your provided code which handles masking logic
        loss_mae_dict = self.mae_loss(
            pred=outputs["mae_pred"],
            target=outputs["mae_target"],
            mask=outputs["mask"]
        )
        l_mae = loss_mae_dict["loss"]

        # 2. Calculate BYOL Loss (Distillation)
        l_byol = self.byol_loss_func(
            outputs["byol_online_pred"],
            outputs["byol_target_proj"]
        )

        # 3. Weighted Sum
        total_loss = (self.lambda_recon * l_mae) + (self.lambda_distill * l_byol)

        return {
            "loss": total_loss,
            "loss_mae": l_mae,
            "loss_byol": l_byol
        }
